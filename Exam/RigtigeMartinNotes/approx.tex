\subsection{Approximation Algorithms}

\subsubsection{Performance Ratios and Schemes}
An algorithm for a problem have an approximation ratio of $\rho(n)$ if, for any
input of size $n$, the cost $C$ of a solution produced by the algorithm is
within a factor of $\rho(n)$ of the cost $C^*$ of an optimal solution:
\[
  \text{max}\left( \frac{C}{C^*}, \frac{C^*}{C} \right) \leq \rho(n).
\]
If an algorithm achieves an approximation ratio of $\rho(n)$, we call it a
$\rho(n)$-approximation algoroithm. These notions apply to both
cost-minimization and cost-maximization problems.

For a miximization problem, $0 < C \leq C^*$, and the ratio $C^*/C$ gives the
factor by which the cost of an optimal solution is larger than the cost of the
approxmiation solution.

Similarly, for a minimization problem, $0 < C^* \leq C$, and the ratio $C/C^*$
gives the factor by which the cost of the approximate solution is larger than
the cost of an optimal solution.

Because we assume the costs are allways positive, the rations are always well
defined, the ratio of an algorithm is never less than 1, since $C/C^* \leq 1$
implies $C^*/C \geq 1$. Therefore a 1-approximation algorithm produce an optimal
solition and an approximation algorithm with a large approximation ratio may
return a solution far worse than optimal.


Below some schemes are outlined which allow us to give a value $\epsilon$ along
with the instance of the problem and achieve an approximation that have a
quality depending on the value.
\begin{description}
\item[Approximation Scheme] for an optimization problem is an approximation
  algorithm that takes as input, not only an instance of the problem, but also a
  value $\epsilon > 0$ such that for any fied $\epsilon$ the scheme is a
  $(1+\epsilon)$-approximation algorithm.

\item[Polynomial-Time Approximation Scheme] is an approximation scheme if for
  any fixed $\epsilon > 0$, the scheme runs in polynomia ltime in the size $n$
  of it's input instance. The running time of such a scheme can increase rapidly
  as $\epsilon$ decreases. For example, the running time of a polynomial-time
  approximation scheme might be $O(n^{(2/\epsilon)})$. Ideally, if $\epsilon$
  decrease by a constant factor, the running time to achieve the desired
  approximation should not incrase by more than a constant factor. (Not
  necessarily by the same factor $\epsilon$ was decreased with.)

\item[Fully Polynomial-Time Approximation Scheme] means the approximation
  algorithm runs in polynomial time in both $1/\epsilon$ and the size $n$ of the
  input instance. I.e. $O((1/\epsilon)^2n^3)$. With such a scheme, a constant
  factor decrease in $\epsilon$ comes with a constant factor increase in
  runningtime.
\end{description}


\subsubsection{Vertex Cover example}

A Vertex Cover of an undirected graph $G = (V,E)$ is a subset $V' \subseteq V$
such that if $(u,v)$is an edge of $G$, then either $u \in V'$ or $v \in V'$ or
both. The size of a vertex cover is the number of vertices in it.

The Vertex Cover Problem is to find a vertex cover of minimum size in a given
undirected graph, this is an optimization version of an NP-Complete decision
problem.

An approximation algorithm that will find a cover that is no more than twice the
size of the optimal cover is written here:
\begin{codebox}
\Procname{$\proc{Approx-Vertex-Cover}(G)$}
\li $C \gets \emptyset$
\li $E' \gets = G.E$
\li \While $E' \neq \emptyset$ \Do
\li   let $(u,v)$ be an arbitrary edge of $E'$
\li   $C = C \cup \{u,v\}$
\li   remove from $E'$ every edge incident on either $u$ or $v$ \End
\li \Return $C$
\end{codebox}
The above algorithm runs in $O(V+E)$.

\graphicc{1.0}{img/approxvertexcover.png}{Example run of the
  \texttt{Approx-Vertex-Cover} algorithm.}{fig:approxvertexcover}

\begin{description}
\item[Theorem 35.1] \texttt{Approx-Vertex-Cover} is a polynomial-time
  2-approximation algorithm.
\item[Proof] It is already shown that the algorithm is a polynomial time
  algorithm.

  The set $C$ of vertices return must be a vertex cover since it loops until
  every edge in $G.E$ have been covered by some vertex.

  To see that the algorithm returns a vertex cover of at most twice the size of
  an optimal cover, let $A$ denote the set of edges that line 4 selects.  To
  cover all the edges in $A$, any vertex cover, in particular the optimal vertex
  cover $C^*$, must include at least one endpoint of each edge in $A$. No two
  edges share endpoints since when an edge is picked, all edges incident on its
  endpoints are removed. Thus no two edges in $A$ are covered by the same vertex
  from $C^*$, and we have the lower bound
  \[
    |C^*| \geq |A|
  \]
  on the size of an optimal vertex cover. Each execution of line 4 picks an edge
  which neither of its endpoints are already in $C$, yielding an upper boind on
  the size of the vertex cover returned
  \[
    |C| = 2|A|
  \]
  Combining the two bounds gives
  \begin{align*}
    |C| &= 2|A| \\
        &\leq 2|C*|
  \end{align*}
  thereby proving the theorem. \qed
\end{description}


\subsubsection{Traveling Salesman Problem}
The TSP is also NP-Complete, the following is a method for approximating an
optimal solution that is at most twice as long as the optimal tour.

It creates a minimum spanning tree using Prims algorithm(see below), and walks along this
tree using a pre-order walk (parent first then child), and uses this as the
solution.

\begin{codebox}
\Procname{$\proc{Approx-TSP-Tour}(G,c)$}
\li select a vertex $r \in G.V$ to be a ``root'' vertex
\li compute a minimum spanning tree $T$ for $G$ from root $r$ \\
    using $\proc{MST-Prim}(G,c,r)$
\li let $H$ be a list of vertices, ordered according to when\\
    they are first visited in a preorder tree walk of $T$
\li \Return the hamiltonian cycle $H$
\end{codebox}

$Q$ is a min-priority queue, $G$ is the graph, $r$ is the root and $w$ is the
weight function. (It basically keeps adding the cheapest edge it can find.)
\begin{codebox}
\Procname{$\proc{MST-Prim}(G,w,r)$}
\li \For each $u \in G.V$ \Do
\li   $u.key \gets \infty$
\li   $u.\pi \gets \const{nul}$ \End
\li $r.key \gets 0$
\li $Q \gets G.V$
\li \While $Q \neq \emptyset$ \Do
\li   $u \gets \proc{Extract-Min}(Q)$
\li   \For each $v \in G.adj[u]$ \Do
\li     \If $v \in Q$ and $w(u,v) < v.key$ \Do
\li       $v.\pi \gets u$
\li       $v.key \gets w(u.v)$
\end{codebox}

The \texttt{Approx-TSP-Tour} Algorithm runs in $\Theta(V^2)$. It's tightly bound
by the inner loop in MST-Prim.

\graphicc{1}{img/approxtsp.png}{A sample run of the approximate TSP algorithm,
  subigure (d) is the resulting tour, and (e) is the optimal tour. Distances are
  simple euclidian distances.}{fig:approxtsp}

\begin{description}
\item[Theorem 35.2] \texttt{Approx-TSP-Tour} is a polynomial-time
  2-approximation algorithm for the traveling salesman problem, with the
  triangle inequality.

\item[Proof] We've already seen that the algorithm runs on polynomial time.  LEt
  $H^*$ denote an optimal tour of a given set of vertices. We obtain a spanning
  tree be deleting any edge from a tour and each edge cost is nonnegative. The
  weight of the MST $T$ calculated in line 2 of \texttt{Approx-TSP-Tour} is a
  lower bound for the cost of an optimal tour:
  \begin{align}
    c(T) &\leq c(H^*) \label{eq:vtch}
  \end{align}
  A full walk list a vertex when it's first visited and on all subsequent
  revisits, lets call a full walk of our tree $W$.  Since the full walk
  traverses every edge of $T$ exactly twice, we have
  \begin{align}
    c(W) &= 2c(T) \label{eq:cw2ct}
  \end{align}
  Combinging Equation \ref{eq:vtch} and \ref{eq:cw2ct} imply that
  \begin{align}
    c(W) &\leq 2c(H^*) \label{eq:cw2ch}
  \end{align}
  and so the cost of $W$ is within a factor of 2 of the cost of an optimal tour.
  A full walk of $T$ is usually not a tour though, since it might visit some
  vertices several times.  By the triangle inequality, we can delete any such
  revisit though without increasing the cost. Doing this for all revisits gives
  a set of vertices corresponding to the-preorder walk of $T$.  Let $H$ be the
  cycle that describes the preorder walk. It is a hamiltonian cycle since every
  vertex is visited once, and it is the cycle computed by
  \texttt{Approx-TSP-Tour}. Since $H$ is created be removing vertices from $W$
  we have
  \begin{align}
    c(H) &\leq c(W) \label{eq:chcw}
  \end{align}
  combining \ref{eq:cw2ch} and \ref{eq:chcw}, gives $c(H) \leq 2c(H^*)$, which
  completes the proof.  \qed
\end{description}

If we drop the assumption that the cost function $c$ satisfies the triangle
inequality, we cannot approximate a tour in polynomial-time unless $P=NP$.

\begin{description}
\item[Theorem 35.3] If $P\neq NP$, then for any constant $\rho \geq 1$, there is
  no polynomial-time approximation algorithm with approximation ratio $\rho$ for
  the general traveling salesman problem.

\item[Proof] This will be a proof by contradiction. Suppose to the contrary that
  for some number $\rho \geq 1$, there is a polynomial-time approximation
  algorithm $A$ with approximation ratio $\rho$. Without loss of generality we
  assume that $\rho$ is an integer, by rounding up if necessary.  We shall then
  show how to use $A$ to solve instances of the Hamiltonian-cycle problem in
  polynomial time. Since the Hamiltonian-cycle problem is NP-Complete a solution
  to the problem would mean $P=NP$.

  Let $G = (V,E)$ be an instance of the Hamiltonian-cycle problem. We wish to
  determine efficiently whether $G$ contains a Hamiltonian cycle by making use of
  the hypothesized approximation algorithm $A$.  We turn $G$ into an instance of
  the traveling-salesman problem as follows. Let $G' = (V,E')$ be a complete
  graph on $V$; that is,
  \[
    E' = \{(u,v) : u,v \in V \text{ and } u\neq v\}.
  \]
  Assign an integer cost to each edge in $E'$ as follows:
  \[
    c(u,v) = \begin{cases}
      1         & \text{if } (u,v) \in E,\\
      \rho|V|+1 & otherwise.
    \end{cases}
  \]
  We can create representations of $G'$ and $c$ from a representation of $G$ in
  time polynomial in $|V|$ and $|E|$.

  Now consider the traveling-salesman problem $(G',c)$. If the original graph
  $G$ has a hamiltonian cycle $H$, then the cost function $c$ assigns to each
  edge of $H$ a cost of 1, and so $(G',c)$ contains a tour of cost $|V|$. On the
  other hand, if $G$ does not contain a hamiltonian cycle, then any tour of $G'$
  must use some edge not in $E$.  But any tour that uses an edge not in $E$ has
  a cost of at least
  \begin{align*}
    (\rho|V|+1)+(|V|-1) &= \rho|V|+|V| \\
                        &> \rho|V|.
  \end{align*}
  Because edges not in $G$ are so costly, there s a gap of at least $\rho|V|$
  between the cost of a tour that is a hamiltonian cycle in $G$ (cost $|V|$) and
  the cost of any other tour (cost at least $\rho|V|+|V|$). Therefore, the cost
  of a tour that is not a hamiltonian cyclein $G$ is at least a factor of
  $\rho+1$ greater than the cost of a tour that is a hamiltonian cycle in $G$.

  Now, suppose that we apply the approximation algorithm $A$ to the
  traveling-salesman problem $(G',c)$. Because $A$ is guaranteed to return a
  tour of cost no more than $\rho$ times the cost of an optimal tour, if $G$
  contains a hamiltonian cycle, then $A$ must return it. If $G$ has no
  hamiltonian cycle, then $A$ returns a tour of cost more than
  $\rho|V|$. THerefore, we can use $A$ to solve the hamiltonian-cycle problem,
  in polynomial time. \qed
\end{description}
