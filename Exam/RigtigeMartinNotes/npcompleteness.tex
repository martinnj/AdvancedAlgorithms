\subsection{NP-Completeness}
Example of a problem in the $P$ class is an Euler Tour(a path in a graph that
uses all edges exactly once, vertices can be visited multible times) of a graph,
it can be done in $O(E)$. An $NP$ class example that is very similar is a
Hamiltonian cycle. A Hamiltonian cycle is a path that visits all vertices once.

We have three classes of problems in this subject:
\begin{itemize*}
\item[\textbf{P}] Problems that are solvable in polynomial time ($O(n^k)$ for
  some constant $k$.)
\item[\textbf{NP}] Problems that are verifiable on polynomial time, i.e. if we
  have a certificate/solution, can we check it in polynomial time. All problems
  in P will also be in NP.
\item[\textbf{NP-Hard}] A subclass of NPC problems that are ``at least as hard
  as the hardest problems in NP'', these cannot be verified in polynomial time.
\item[\textbf{NPC}] Problems that are both in the set of NP problems and NP-hard
  problems. (NP $\cap$ NP-Hard)
\end{itemize*}

\subsubsection{Decision problems vs. optimization problems}
NP-completeness does not cover optimization problems, only decision problems. We
can however use the relationship between optimization and decision problems to
guage if a optimization problems is in fact NP-complete.

The shortest-path problem is an opimization problem, but can converted (in
polynomial time) to a decision problem if the question is posed like so: ``Does
a path $p$ in the graph $G$ exist with only $k$ edges?'', then we iterate over
$k$ and will be able to guage the shortest bath problem as a dicision problem.

\subsubsection{Reduction}
The notion of showing that one problem us no harder or no easier than another
problem applies even when both problems are decision problems. This is used in
almost all NP-Completeness proof as follows: Take an instance $\alpha$ of
problem $A$, that is, a specific input for the problem $A$, so for shortest path
we may choose a graph $G$, and vertices $u$ and $v$ as well as a $k$. Make a
polynomial time transofmration from $\alpha$ to instance $\beta$ of problem $B$
(which can be decided in polynomial time) with the following characteristics:
\begin{enumerate*}
\item Transformation takes polynomial time.
\item The answers are the same. The answer for $\alpha$ is ``yes'', iff. the
  answer for $\beta$ is ``yes'', same for ``no''.
\end{enumerate*}
Such an algorithm is called a reduction algorithm.

We can now solve any instance of $A$ in polynomial time by converting $\alpha$
to $\beta$ in polynomial time, running the polynomial time decision algorithm
for $B$ and using the answer for $B$ as the answer for $A$.


Since NP-Completeness is usually how showing how hard a problem is we can use
polynomial time reduction algorithms in the opposite way to show that a problem
is NP-Ciomplete. Lets show that for some problem $B$ there can be no polynomial
time algorithm.

Suppose we have a dicision problem $A$, which we know that no polynomial time
algorithm cat exist. Suppose we also have a polynomial time reduction algorithm
that can reduce instances of $A$ into instances of $B$ instead. Now, suppose
otherwise, if $B$ had a polynomial time algorithm, we would be able to reduce
$A$ to $B$ and have a polynomial time algorithm for $A$, which we assummed could
not exist, which is a contradiction.

\subsubsection{Abstract Problems}
We define the abstract problem $Q$ to be the binary relationship between an
instance in the set $I$ and a solution.  For our shortest path problem, the
instance would be a triple of input $i = (G,u,v)$ and the solution $s$ would be
a series of vertices. Since NP-Completenes is about decision problems, the input
would instead be $i = (G,u,v,k)$ and the output would be $s =
\{0,1\}$. Resulting in a deicions problem like so $\text{PAth}(i) = 1$(yes) if a
path exists in $G$ between $u$ and $v$ using $k$ vertices. and $\text{PAth}(i) =
0$(no) otherwise. We thus rely on the ability to recast optimization problems as
decision problems in order to make decisions about their NP-Completeness.


\subsubsection{Formal Language Framework}
$\Sigma$ is an alpjanet, a language $L$ over the alphabet $\Sigma$ is any
combination of symbols from $\Sigma$.  For instance if $\Sigma = \{0,1\}$ we can
have $L = \{0,1,10,11,101,110,111 , ...\}$. We denote the empty string as
$\epsilon$ and the empty language as $\emptyset$, and the language of all
strings over $\Sigma$ as $\Sigma^*$.  For instance if $\Sigma = \{0,1\}$ then
$\Sigma^* = \{\epsilon,0,1,10,11,100,101,110,111,1000,...\}$. Every language
$L$over $\Sigma$ is a subset of $\Sigma^*$.

We can perform several operations on languages, set operations such as union and
intersect, or the complement of a lanaugege $L$ as $\overline{L} = \Sigma^* -
L$. The concatenation $L_1L_2$ of two languages is
\[
  L = \{x_1x_2 : x_1 \in L_1 \text{ and } x_2 \in L_2\}.
\]
The closure or Kleene star of a language is
\[
  L^* = \{\epsilon\}\cup L\cup L^2 \cup L^3 \cup ... ,
\]
where $L^k$ os the language obtained by concatenating L to itself $k$ times.





\todo[inline]{Continue from p. 1058.}